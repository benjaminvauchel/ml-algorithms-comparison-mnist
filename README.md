# MNIST Handwritten Digit Classification Study

This mini-project focuses on classifying handwritten digits (0-9) from the MNIST dataset. The MNIST dataset contains 70,000 black and white images, each 28x28 pixels. The primary goal is to accurately classify these images into their respective 10 classes. The objective of the project is to test and compare different methods for image classification, including traditional algorithms and neural networks, in order to evaluate their performance on this benchmark dataset.

The Jupyter Notebook was created as part of the Machine Learning course at École des Mines de Saint-Étienne and was co-authored by Alexis BECHET.

## Dataset

The project utilizes the **MNIST dataset**, which is loaded via Keras.
The dataset consists of:
* 70,000 images in total, split into:
    * `X_train`: 60,000 images for training, with a shape of (60000, 28, 28).
    * `X_test`: 10,000 images for testing, with a shape of (10000, 28, 28).
* Corresponding labels `y_train` (60000,) and `y_test` (10000,) for the training and testing sets, respectively.
* Each image is a 28x28 pixel grayscale image of a handwritten digit.

## Dependencies

The following Python libraries are used in this project:

* `numpy` for numerical operations
* `matplotlib` for data visualization and plotting
* `sklearn` (scikit-learn) for machine learning models and utilities
* `tensorflow` with `keras` for machine learning models and for loading the MNIST dataset

## Usage

The `main.ipynb` notebook contains the full implementation of the project along with the corresponding explanations. To run the notebook and reproduce the results:

1.  Ensure you have all the dependencies listed above installed in your Python environment.
2.  Open the `main.ipynb` file in a Jupyter environment (e.g., Jupyter Notebook, Google Colab).
3.  Run the cells sequentially to load the data, preprocess it, train the models, and evaluate their performance.

## Models Used

The project involves the use of various machine learning models from the `sklearn` library for classification, including but not limited to:

- **Unsupervised methods**: K-Means and EM with Gaussian mixture
- **Supervised methods**: Decision Tree, Support Vector Machine, (multiclass) Logistic Regression, Naïve Bayes Classifier, MLP, CNN

Additionally, **PCA** (Principal Component Analysis) is used for dimensionality reduction.

## Results

(Please run the `main.ipynb` notebook to read the explanation and view the classification results, evaluation metrics, and any visualizations generated by the models.)

## Licence

This project is provided for academic purposes. Feel free to explore, modify, or build upon it.
